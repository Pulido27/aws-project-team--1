import multiprocessing
import logging
import struct
import json
import time
import re
from pathlib import Path
from gen_dic import indices  # Importar diccionario
        
def dividir_carpetas(ruta, num_procesos):
    carpetas = [carpeta for carpeta in ruta.iterdir() if carpeta.is_dir()]
    tamaño_bloque = len(carpetas) // num_procesos
    partes = [carpetas[i:i + tamaño_bloque] for i in range(0, len(carpetas), tamaño_bloque)]

    if len(partes) > num_procesos:
        partes[-2].extend(partes[-1])
        partes.pop()

    return partes

def procesar_carpetas(parte,cola1,indices):
    # Buffer para escritura en batch (reduce accesos a disco)
    buffer = {}
    for carpeta in parte:

        ruta_json = carpeta / "metadata.json"
        contenidoJson = ruta_json.read_text(encoding='utf-8')
        objPy = json.loads(contenidoJson)
            
        ruta_txt = carpeta / f"{carpeta.name}_djvu.txt"
        contenidoTxt = ruta_txt.read_text(encoding='utf-8')   
        
        # Estructura SET donde se guardaran las palabras para no realizar procesos extras con las palabras que se repiten
        palabrasLib = set()
        # Variable donde se ira creando cada palabra
        palabra = []
        # Variable para guardar el titulo
        titulo = objPy["title"]

        words = re.findall(r'\b[a-zA-Z]+\b', contenidoTxt)
        for word in words:
            palabrasLib.add(word.lower())

        for palabra in palabrasLib:
            if len(palabra) > 3 and len(palabra) < 15:

                # Agregar a buffer de escritura
                if palabra not in buffer:
                    buffer[palabra] = []
                        
                # Guardar la posicion del index
                buffer[palabra].append(struct.pack("I", indices[titulo]))


        if len(buffer) > 500000:
            cola1.put(buffer)
            buffer = {}

    cola1.put(buffer)
    cola1.put(None)
    

def escribir_bin(cola1,num_procesos):
    buffers = {}
    contador = 0
    while contador < num_procesos or not cola1.empty():
        try:
            buffer = cola1.get(timeout=10)

        except:
            continue
        if buffer == None:
            contador += 1
        else:
            for clave, valor in buffer.items():
                if clave in buffers:
                    buffers[clave].extend(valor)
                else:
                    buffers[clave] = valor
        
            if len(buffers) > 1000000:
                for palabra, data in buffers.items():
        
                    palabra_ruta = Path(f"/home/ubuntu/python_code/work/y/{palabra}") 
                
                    with palabra_ruta.open("ab") as f:
                        # Escribir todo el buffer de una vez
                        bin_info = b''.join(data)
                        f.write(bin_info)
                buffers.clear()
   
    for palabra, data in buffers.items():
            
        palabra_ruta = Path(f"/home/ubuntu/python_code/work/y/{palabra}") 
                    
        with palabra_ruta.open("ab") as f:
            # Escribir todo el buffer de una vez
            bin_info = b''.join(data)
            f.write(bin_info)

if __name__ == "__main__":
    cola1 = multiprocessing.Queue()
    cola2 = multiprocessing.Queue()
    

    ruta = Path("/home/ubuntu/python_code/work/muestras") 
        
    # Crear y lanzar los procesos
    num_procesos = 11
    partes_carpetas = dividir_carpetas(ruta,num_procesos)   

    procesos = []
    for parte in partes_carpetas:
        p = multiprocessing.Process(target=procesar_carpetas, args=(parte, cola1, indices))
        procesos.append(p)
        p.start()

    p2 = multiprocessing.Process(target=escribir_bin, args=(cola1,num_procesos))
    p2.start()

    # Esperar a que todos los procesos terminen
    for p in procesos:
        p.join()
        
    p2.join()
    
    